{
  "1 Matières, formations et groupes": {
    "Matière liée au projet": {
      "value": "2025-5A-IABD-DRL",
      "page": 1
    },
    "Formations": {
      "value": "-",
      "page": 1
    },
    "Nombre d'étudiant par groupe": {
      "value": "3 à 4",
      "page": 1
    },
    "Règles de constitution des groupes": {
      "value": "Imposé",
      "page": 1
    },
    "Charge de travail estimée par étudiant": {
      "value": "30,00 h",
      "page": 1
    }
  },
  "2 Sujet(s) du projet": {
    "Type de sujet": {
      "value": "Imposé",
      "page": 1
    }
  },
  "3 Détails du projet": {
    "Objectif du projet (à la fin du projet les étudiants sauront réaliser un...)": {
      "value": "",
      "page": 1
    },
    "Descriptif détaillé": {
      "value": "Environnements de départ : - pour tests : Line World - pour tests : Grid World - pour tests : TicTacToe versus Random + 1 au choix parmi : - Farkle (solo ou vs Random ou Heuristique) > https://boardgamearena.com/gamepanel?game=farkle - LuckyNumbers (vs Random ou Heuristique) > https://boardgamearena.com/gamepanel?game=luckynumbers - Pond (versus Random ou Heuristique) > https://boardgamearena.com/gamepanel?game=pond Types d'agents à étudier : - Random - TabularQLearning (quand possible) - DeepQLearning - DoubleDeepQLearning - DoubleDeepQLearningWithExperienceReplay - DoubleDeepQLearningWithPrioritizedExperienceReplay - REINFORCE - REINFORCE with mean baseline - REINFORCE with Baseline Learned by a Critic - PPO A2C style - RandomRollout - Monte Carlo Tree Search (UCT) - Expert Apprentice - Alpha Zero - MuZero - MuZero stochastique Métriques à obtenir (attention métriques pour la policy obtenue, pas pour la policy en mode entrainement) : - Score moyen (pour chaque agent) au bout de 1000 parties d'entrainement - Score moyen (pour chaque agent) au bout de 10 000 parties d'entrainement - Score moyen (pour chaque agent) au bout de 100 000 parties d'entrainement - Score moyen (pour chaque agent) au bout de 1 000 000 parties d'entrainement (si possible) - Score moyen (pour chaque agent) au bout de XXX parties d'entrainement (si possible) - Temps moyen mis pour exécuter un coup Si la partie est de durée variable : - Longueur moyenne (nombre de step) d'une partie au bout de 1000 parties d'entrainement - Longueur moyenne (nombre de step) d'une partie au bout de 10 000 parties d'entrainement - Longueur moyenne (nombre de step) d'une partie au bout de 100 000 parties d'entrainement - Longueur moyenne (nombre de step) d'une partie au bout de 1 000 000 parties d'entrainement (si possible) - Longueur moyenne d'une partie au bout de XXX parties (si possible) Il sera également nécessaire de présenter une interface graphique permettant de regarder jouer chaque agent et également de mettre à disposition un agent 'humain'. Pour chaque environnement et chaque algorithme, les étudiants devront étudier les performances de l'algorithme et retranscrire leur résultats. Les étudiants devront fournir l'intégralité du code leur ayant permis d'obtenir leurs résultats ainsi que les modèles (keras/tensorflow/pytorch/jax/keras_core/burn) entraînés et sauvegardés prêts à être exécutés pour confirmer les résultats présentés. Les étudiants devront présenter ces résultats dans un rapport ainsi qu'une présentation. Dans ces derniers, les étudiants devront faire valoir leur méthodologie de choix d'hyperparamètres, et proposer leur interprétation des résultats obtenus",
      "page": 1
    },
    "Ouvrages de référence (livres, articles, revues, sites web...)": {
      "value": "",
      "page": 1
    },
    "Outils informatiques à installer": {
      "value": "",
      "page": 1
    }
  },
  "4 Livrables et étapes de suivi": [
    {
      "value": "Étape 1: Etape intermédiaire - 1er Gameplay choisi Implémenté - Simulation de jeu avec joueur random (calculer le nombre de parties / seconde) - Jeu avec Joueur humain + GUI - Proposition de description de l'état du jeu (vecteur d'encoding) - Proposition de description d'une action du jeu (vecteur d'encoding) Rendu : (tout sur MyGES, pas simplement un lien git) > code source > démonstration rapide > documents de spécifications (encoding vectors) - Date de rendu: lundi 07/10/2024 23h59",
      "page": 3
    },
    {
      "value": "Étape 3: Rendu final - Soutenance Rendu : (tout sur MyGES, pas simplement un lien git) > code source > démonstration rapide > Readme de reproduction des résulats / lancement démo > Rapport conséquent sur les expérimentations menées / résultats obtenus et observations critiques de ces résultats > documents de résultats (metrics sur les 1 gameplays avec tous les algos) > Slides de présentation utilisés pour la soutenance - Date de rendu: mardi 03/12/2024 10h00",
      "page": 3
    }
  ],
  "5 Soutenance": {
    "Durée de présentation par groupe": {
      "value": "20 min",
      "page": 3
    },
    "Audience": {
      "value": "A huis clos",
      "page": 3
    },
    "Type de présentation": {
      "value": "Présentation / PowerPoint",
      "page": 3
    },
    "Précisions": {
      "value": "",
      "page": 3
    }
  }
}